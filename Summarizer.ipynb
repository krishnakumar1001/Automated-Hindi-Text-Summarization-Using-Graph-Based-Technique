{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the percentage of summary you want of original paragraph 25\n",
      "\n",
      "\n",
      "शिक्षा सभी के जीवन को सकारात्मक तरीके से प्रभावित करती है और हमें जीवन की सभी छोटी और बड़ी समस्याओं का समाना करना सिखाती है\n",
      "बिना शिक्षा के जीवन लक्ष्य रहित और कठिन हो जाता है\n",
      "इसलिए हमें शिक्षा के महत्व और दैनिक जीवन में इसकी आवश्यकता को समझना चाहिए\n",
      " इस प्रकार एक देश का व्यापक विकास उस में देश में नागरिकों के लिए उपलब्ध प्रचलित शिक्षा प्रणाली पर निर्भर करता है\n",
      "देश में हर क्षेत्र में नागरिकों के लिए अच्छी और उचित शिक्षा प्रणाली को उपलब्ध कराए जाने के सामान्य लक्ष्य को निर्धारित किया जाना चाहिए और शिक्षा प्राप्ति के रास्ते को सुगम व सुलभ्य बनाए जाने की कोशिश की जानी चाहिए\n",
      "शिक्षा सबसे महत्वपूर्ण तंत्र है जो व्यक्ति के जीवन के साथ ही देश के विकास में भी महत्वपूर्ण भूमिका निभाती है।आजकल यह किसी भी समाज की नई पीढ़ी के उज्ज्वल भविष्य के लिए एक महत्वपूर्ण कारक बन गयी है।शिक्षा के महत्व को ध्यान में रखते हुए सरकार के द्वारा  साल से  साल तक की आयु वाले सभी बच्चों के लिए शिक्षा को अनिवार्य कर दिया गया है।शिक्षा सभी के जीवन को सकारात्मक तरीके से प्रभावित करती है और हमें जीवन की सभी छोटी और बड़ी समस्याओं का समाना करना सिखाती है।समाज में सभी के लिए शिक्षा की ओर इतने बड़े स्तर पर जागरुक करने के बाद भी देश के विभिन्न क्षेत्रों में शिक्षा का प्रतिशत अभी भी समान है।पिछड़े क्षेत्रों में रहने वाले लोगों के लिए अच्छी शिक्षा के उचित लाभ प्राप्त नहीं हो रहे हैं क्योंकि उनके पास धन और अन्य साधनों की कमी है।यद्यपि इन क्षेत्रों में इस समस्या को सुलझाने के लिए सरकार द्वारा कुछ नई और प्रभावी रणनीतियों की योजना बनाकर लागू किया गया है।शिक्षा ने मानसिक स्थिति को सुधारा है और लोगों के सोचने के तरीके को बदला है।यह आगे बढ़ने और सफलता और अनुभव प्राप्त करने के लिए आत्मविश्वास लाती है और सोच को कार्य रुप में बदलती है।बिना शिक्षा के जीवन लक्ष्य रहित और कठिन हो जाता है।इसलिए हमें शिक्षा के महत्व और दैनिक जीवन में इसकी आवश्यकता को समझना चाहिए।हमें पिछड़े क्षेत्रों में लोगों को शिक्षा के महत्व को बताकर इसे प्रोत्साहन देना चाहिए।विकलांग और गरीब व्यक्तियों को भी अमीर और सामान्य व्यक्तियों की तरह वैश्विक विकास प्राप्त करने के लिए शिक्षा की समान आवश्यकता है और उन्हें समान अधिकार भी प्राप्त है।हम में से सभी को उच्च स्तर पर शिक्षित होने के लिए अपने सबसे अच्छे प्रयासों को करने के साथ ही सभी की शिक्षा तक पहुँच को संभव बनाना चाहिए जिसमें सभी गरीब और विकलांग व्यक्ति वैश्विक आधार पर भाग ले सकें।कुछ लोग ज्ञान और कौशल की कमी के कारण पूरी तरह से अशिक्षित रहकर बहुत दर्दनाक जीवन जीते हैं। कुछ लोग शिक्षित होते हैं लेकिन पिछड़े इलाकों में उचित शिक्षा प्रणाली के अभाव के कारण अपने दैनिक कार्यों के लिए धन जोड़ने में भी पर्याप्त कुशल नहीं होते।इस प्रकार हमें सभी के लिए अच्छी शिक्षा प्रणाली को प्राप्त करने के समान अवसर देने की कोशिश करनी चाहिए चाहे वो गरीब हो या अमीर। एक देश नागरिकों के वैयक्तिक विकास और वृद्धि के बिना विकसित नही हो सकता। इस प्रकार एक देश का व्यापक विकास उस में देश में नागरिकों के लिए उपलब्ध प्रचलित शिक्षा प्रणाली पर निर्भर करता है।देश में हर क्षेत्र में नागरिकों के लिए अच्छी और उचित शिक्षा प्रणाली को उपलब्ध कराए जाने के सामान्य लक्ष्य को निर्धारित किया जाना चाहिए और शिक्षा प्राप्ति के रास्ते को सुगम व सुलभ्य बनाए जाने की कोशिश की जानी चाहिए।इस तरह देश अपने चहुँमुखी विकास की ओर अग्रसर होगा।\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "# for reading input file\n",
    "text=open(\"hindi1.txt\", encoding=\"utf8\").read()\n",
    "#Title of the Text\n",
    "title=u\"शिक्षा का महत्व\"\n",
    "#for removing punctuation from sentences\n",
    "\n",
    "text = re.sub(r'(\\d+)', r'', text)\n",
    "text = text.replace('\\n', '')\n",
    "text = text.replace(u',', '')\n",
    "text = text.replace(u'\"', '')\n",
    "text = text.replace(u'(', '')\n",
    "text = text.replace(u')', '')\n",
    "text = text.replace(u'\"', '')\n",
    "text = text.replace(u':', '')\n",
    "text = text.replace(u\"'\", '')\n",
    "text = text.replace(u\"’\", '')\n",
    "text = text.replace(u\"‘\", '')\n",
    "text = text.replace(u\"‘‘\", '')\n",
    "text = text.replace(u\"’’\", '')\n",
    "text = text.replace(u\"''\", '')\n",
    "text = text.replace(u\".\", '')\n",
    "text=text.replace(u'?', u'।')\n",
    "\t\n",
    "sentences=text.split(u\"।\")\n",
    "#print(sentences)\n",
    "tokens = []\n",
    "for each in sentences:            \n",
    "\t\t\tword_list = each.split()\n",
    "\t\t\ttokens = tokens + word_list\n",
    "\t\t   #print(tokens)\n",
    "stop_removed_tokens=[]\n",
    "f = open(\"stopwords.txt\", encoding=\"utf8\")\n",
    "stopwords = [x.strip()  for  x  in  f.readlines()]\n",
    "tokens = [i for i in tokens if i not in stopwords]\n",
    "stop_removed_tokens = tokens\n",
    "\t\t\n",
    "#print(stop_removed_tokens)\n",
    "def generate_stem_words( word):\n",
    "\tsuffixes = {1: [u\"ो\", u\"े\", u\"ू\", u\"ु\", u\"ी\", u\"ि\", u\"ा\"],\n",
    "\t\t\t\t2: [u\"कर\", u\"ाओ\", u\"िए\", u\"ाई\", u\"ाए\", u\"ने\", u\"नी\", u\"ना\", u\"ते\", u\"ीं\", u\"ती\", u\"ता\", u\"ाँ\", u\"ां\", u\"ों\",\n",
    "\t\t\t\tu\"ें\"],\n",
    "\t\t\t\t3: [u\"ाकर\", u\"ाइए\", u\"ाईं\", u\"ाया\", u\"ेगी\", u\"ेगा\", u\"ोगी\", u\"ोगे\", u\"ाने\", u\"ाना\", u\"ाते\", u\"ाती\", u\"ाता\",\n",
    "\t\t\t\tu\"तीं\", u\"ाओं\", u\"ाएं\", u\"ुओं\", u\"ुएं\", u\"ुआं\"],\n",
    "\t\t\t\t4: [u\"ाएगी\", u\"ाएगा\", u\"ाओगी\", u\"ाओगे\", u\"एंगी\", u\"ेंगी\", u\"एंगे\", u\"ेंगे\", u\"ूंगी\", u\"ूंगा\", u\"ातीं\",\n",
    "\t\t\t\tu\"नाओं\", u\"नाएं\", u\"ताओं\", u\"ताएं\", u\"ियाँ\", u\"ियों\", u\"ियां\"],\n",
    "\t\t\t\t5: [u\"ाएंगी\", u\"ाएंगे\", u\"ाऊंगी\", u\"ाऊंगा\", u\"ाइयाँ\", u\"ाइयों\", u\"ाइयां\"],\n",
    "\t\t\t\t}\n",
    "\tfor L in 5, 4, 3, 2, 1:\n",
    "\t\tif len(word) > L + 1:\n",
    "\t\t\tfor suf in suffixes[L]:\n",
    "\t\t\t\tif word.endswith(suf):\n",
    "\t\t\t\t\treturn word[:-L]\n",
    "\treturn word\n",
    "\n",
    "def generate_stem_dict():\n",
    "\tstem_word = {}\n",
    "\tstemmed_word = []\n",
    "\tfor each_token in tokens:\t\t\t\t\t\n",
    "\t\ttemp = generate_stem_words(each_token)\n",
    "\t\tstem_word[each_token] = temp\n",
    "\t\tstemmed_word.append(temp)\n",
    "\treturn stem_word\n",
    "generate_stem_dict()\n",
    "tokens=stop_removed_tokens\n",
    "#print(tokens)\n",
    "#tokens = list (set(tokens))\n",
    "#Making word frequency  in dictinary datastructure\n",
    "freqTable = dict()\n",
    "for word in tokens:\n",
    "\tif word in freqTable:\n",
    "\t\tfreqTable[word] += 1\n",
    "\telse:\n",
    "\t\tfreqTable[word] = 1\n",
    "#printing the Frequency of Words\n",
    "\n",
    "#Tokenizing The Sentences\n",
    "sentences=text.split(u\"।\")\n",
    "\n",
    "#making sentenceValue dictionary and giving a sentenceValue(rank) through freqTable dictionary of words.\n",
    "sentenceValue = dict()\n",
    "for sentence in sentences:\n",
    "\tfor wordValue in freqTable:\n",
    "\t\tif sentence in sentenceValue:\n",
    "\t\t\tsentenceValue[sentence] += freqTable[wordValue]\n",
    "\t\telse:\n",
    "\t\t\tsentenceValue[sentence] = freqTable[wordValue]\n",
    "\n",
    "#Normalize the value of sentence rank as 0 to 1\n",
    "for sentence in sentenceValue:\n",
    "\tsentenceValue[sentence]=(sentenceValue[sentence]*(1.000000))/max(sentenceValue.values())\n",
    "\n",
    "\n",
    "#sentence length feature\n",
    "\n",
    "sentenceLength=dict()\n",
    "\n",
    "def sentence_length(sentences):\n",
    "\tMinL=4              # minm len of sentence\n",
    "\tMaxL=18\t\t\t\t# maxm len of sentence\n",
    "\tMintheta=0 \t\t\t# minm angle theta\n",
    "\tMaxtheta=180\t\t# maxm angle theta\n",
    "\tfor sentence in sentences:\n",
    "\t\tL=sentence.split()\n",
    "\t\tL=len(L)\n",
    "\t\tif ((L<MinL)or(L>MaxL)):     # if senLength less than MinLength or Grtr than MaxLen then ignore the sentence\n",
    "\t\t\tsentenceLength[sentence]=0\n",
    "\t\telse:\n",
    "\t\t\tSl=math.sin((L-MinL)*((Maxtheta-Mintheta)/(MaxL-MinL)))   # calculate the sentence\n",
    "\t\t\tsentenceLength[sentence]=Sl\n",
    "\treturn sentenceLength\n",
    "sentence_length(sentences)   # calling sentence_length function\n",
    "\n",
    "\n",
    "#sentence position feature\n",
    "sentencePosition=dict()\n",
    "sentenceNumber=dict()\n",
    "def sentence_position(sentences):\n",
    "\tTRSH=0.01\n",
    "\tMintheta=0\n",
    "\tMaxtheta=360\n",
    "\tCP=1\n",
    "\tMinV=len(sentences)*TRSH\n",
    "\tMaxV=len(sentences)*(1-TRSH)\n",
    "\tfor sentence in sentences:\n",
    "\t\tif ((CP==1) or (CP==len(sentences))):    #if sentence postion is 1st or last then its important\n",
    "\t\t\tsentencePosition[sentence]=1\n",
    "\t\t\tsentenceNumber[sentence]=CP\n",
    "\t\telse:\n",
    "\t\t\tSP=math.cos((CP-MinV)*((Maxtheta-Mintheta)/(MaxV-MinV)))   # calculating sentence position\n",
    "\t\t\tsentencePosition[sentence]=SP\n",
    "\t\t\tsentenceNumber[sentence]=CP\n",
    "\t\tCP=CP+1\n",
    "\treturn sentencePosition\n",
    "\n",
    "sentence_position(sentences)\n",
    "\n",
    "#print(sentenceNumber)\n",
    "\n",
    "\n",
    "sentencesTitle=dict()\n",
    "#sentence title feature\n",
    "def sentences_title(sentences,title):\n",
    "\ttitle_word=title.split()\n",
    "\tfor sentence in sentences:\n",
    "\t\tcount=0\n",
    "\t\ttemp=sentence\n",
    "\t\tsentence=sentence.split()\n",
    "\t\tfor word_in_title in title_word:\n",
    "\t\t\tword_in_title=word_in_title.lower()\n",
    "\t\t\tfor sentence_word in sentence:\n",
    "\t\t\t\tsentence_word=sentence_word.lower()\n",
    "\t\t\t\tif sentence_word==word_in_title:\n",
    "\t\t\t\t\tcount=count+1\n",
    "\t\tsentencesTitle[temp]=(count*1.000)/len(title_word)\n",
    "\treturn sentencesTitle\n",
    "sentences_title(sentences,title)\n",
    "\n",
    "\n",
    "#sentence Similarity feature by Graph\n",
    "#sentence Similarity feature by Graph\n",
    "#sentence Similarity feature by Graph\n",
    "\n",
    "sentToken= [] #each sentence containg token\n",
    "for sent in sentences:\n",
    "    temp=sent.split()\n",
    "    f = open(\"stopwords.txt\", encoding=\"utf8\")\n",
    "    stopwords = [x.strip() for x in f.readlines()]\n",
    "    token = [i for i in temp if i not in stopwords]\n",
    "    sentToken.append(token)\n",
    "\n",
    "#print(sentToken)\n",
    "#retuen weight of two sentences\n",
    "def weight(i,j):\n",
    "    sent1=sentToken[i]\n",
    "    sent2=sentToken[j]\n",
    "    return len(list(set(sent1).intersection(sent2)))\n",
    "\n",
    "sentLen=len(sentences)\n",
    "\n",
    "sentencesGraph= [[0 for x in range(sentLen)] for y in range(sentLen)]\n",
    "for i in range(0,sentLen):\n",
    "    for j in range(0,sentLen):\n",
    "        if i!=j:\n",
    "            sentencesGraph[i][j] = weight(i, j)\n",
    "        else:\n",
    "            sentencesGraph[i][j]=0\n",
    "\n",
    "\n",
    "senSimlariy= []\n",
    "sum=0\n",
    "for i in range(0,sentLen):\n",
    "    for j in range(0,sentLen):\n",
    "        sum +=sentencesGraph[i][j]\n",
    "    senSimlariy.append(sum)\n",
    "    sum=0\n",
    "sentencesSimilarity=dict()\n",
    "i=0 # indexing the sentence similarity sentences\n",
    "for sentence in sentences:\n",
    "    sentencesSimilarity[sentence] = senSimlariy[i] / max(senSimlariy)\n",
    "    i +=1\n",
    "\n",
    "#sentence Feature add for ranking of sentences\n",
    "sentenceRanking=dict()\n",
    "def sentence_ranking(sentences):\n",
    "    f5 = sentencesSimilarity\n",
    "    f1=sentenceValue\n",
    "    f2=sentenceLength\n",
    "    f3=sentencePosition\n",
    "    f4=sentencesTitle\n",
    "    for sentence in sentences:\n",
    "        temp=abs(f1[sentence])+abs(f2[sentence])+abs(f3[sentence])+abs(f4[sentence])+abs(f5[sentence])\n",
    "        sentenceRanking[sentence]=temp\n",
    "    return sentenceRanking\n",
    "sentence_ranking(sentences)\n",
    "\n",
    "# function to calculate summary\n",
    "sentenceSummary=dict()\n",
    "def summary():\n",
    "\tsenLength=len(sentences)\n",
    "\tpercent = int(input(\"Enter the percentage of summary you want of original paragraph \"))\n",
    "\tcount = int (senLength * (percent / 100))\n",
    "\tif count > senLength:\n",
    "\t\tprint(\"Wrong Input..must be less than original sentence length.\")\n",
    "\n",
    "\ttemp=0\n",
    "\tsentence_Ranking = sorted(sentenceRanking.items() , key=lambda t : t[1] , reverse=True)  #sorting sentence_Rank dict in reverse order\n",
    "\tfor k in sentence_Ranking:\n",
    "\t\tif temp<count:\n",
    "\t\t\tsentenceSummary[sentenceNumber[k[0]]]= k[0]\n",
    "\t\t\ttemp=temp+1\n",
    "\t\telse:\n",
    "\t\t\treturn 0\n",
    "summary()  # calling summary function\n",
    "#print(sentenceSummary)\n",
    "print('\\n')\n",
    "sentence_summary=sorted(sentenceSummary.items())\n",
    "for x in sentence_summary:\n",
    "\tprint(x[1])\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
