{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the percentage of summary you want of original paragraph 30\n",
      "\n",
      "\n",
      "प्रधानमंत्री नरेंद्र मोदी के चीन दौरे के बाद एक खुशखबरी आई है|\n",
      "व्यापारियों ने उम्मीद जताई कि इस साल भारत और चीन के बीच किसी भी तरह की समस्या नहीं आएगी और व्यापार जारी रहेगा|\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "# for reading input file\n",
    "text = open(\"indiaChina.txt\", encoding=\"utf8\").read()\n",
    "\n",
    "# for removing punctuation from sentences\n",
    "\n",
    "text = re.sub(r'(\\d+)', r'', text)\n",
    "text = text.replace('\\n', '')\n",
    "text = text.replace(u',', '')\n",
    "text = text.replace(u'\"', '')\n",
    "text = text.replace(u'(', '')\n",
    "text = text.replace(u')', '')\n",
    "text = text.replace(u'\"', '')\n",
    "text = text.replace(u':', '')\n",
    "text = text.replace(u\"'\", '')\n",
    "text = text.replace(u\"’\", '')\n",
    "text = text.replace(u\"‘\", '')\n",
    "text = text.replace(u\"‘‘\", '')\n",
    "text = text.replace(u\"’’\", '')\n",
    "text = text.replace(u\"''\", '')\n",
    "text = text.replace(u\".\", '')\n",
    "text = text.replace(u'?', u'।')\n",
    "\n",
    "sentences = text.split(u\"।\")\n",
    "# print(sentences)\n",
    "tokens = []\n",
    "for each in sentences:\n",
    "    word_list = each.split()\n",
    "    tokens = tokens + word_list\n",
    "\n",
    "# print(tokens)\n",
    "stop_removed_tokens = []\n",
    "f = open(\"stopwords.txt\", encoding=\"utf8\")\n",
    "stopwords = [x.strip() for x in f.readlines()]\n",
    "tokens = [i for i in tokens if i not in stopwords]\n",
    "stop_removed_tokens = set(tokens)\n",
    "\n",
    "\n",
    "# print(stop_removed_tokens)\n",
    "def generate_stem_words(word):\n",
    "    suffixes = {1: [u\"ो\", u\"े\", u\"ू\", u\"ु\", u\"ी\", u\"ि\", u\"ा\"],\n",
    "                2: [u\"कर\", u\"ाओ\", u\"िए\", u\"ाई\", u\"ाए\", u\"ने\", u\"नी\", u\"ना\", u\"ते\", u\"ीं\", u\"ती\", u\"ता\", u\"ाँ\", u\"ां\",\n",
    "                    u\"ों\",\n",
    "                    u\"ें\"],\n",
    "                3: [u\"ाकर\", u\"ाइए\", u\"ाईं\", u\"ाया\", u\"ेगी\", u\"ेगा\", u\"ोगी\", u\"ोगे\", u\"ाने\", u\"ाना\", u\"ाते\", u\"ाती\",\n",
    "                    u\"ाता\",\n",
    "                    u\"तीं\", u\"ाओं\", u\"ाएं\", u\"ुओं\", u\"ुएं\", u\"ुआं\"],\n",
    "                4: [u\"ाएगी\", u\"ाएगा\", u\"ाओगी\", u\"ाओगे\", u\"एंगी\", u\"ेंगी\", u\"एंगे\", u\"ेंगे\", u\"ूंगी\", u\"ूंगा\", u\"ातीं\",\n",
    "                    u\"नाओं\", u\"नाएं\", u\"ताओं\", u\"ताएं\", u\"ियाँ\", u\"ियों\", u\"ियां\"],\n",
    "                5: [u\"ाएंगी\", u\"ाएंगे\", u\"ाऊंगी\", u\"ाऊंगा\", u\"ाइयाँ\", u\"ाइयों\", u\"ाइयां\"],\n",
    "                }\n",
    "    for L in 5, 4, 3, 2, 1:\n",
    "        if len(word) > L + 1:\n",
    "            for suf in suffixes[L]:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-L]\n",
    "    return word\n",
    "\n",
    "\n",
    "def generate_stem_dict():\n",
    "    stem_word = {}\n",
    "    stemmed_word = []\n",
    "    for each_token in tokens:\n",
    "        temp = generate_stem_words(each_token)\n",
    "        stem_word[each_token] = temp\n",
    "        stemmed_word.append(temp)\n",
    "    return stem_word\n",
    "\n",
    "\n",
    "generate_stem_dict()\n",
    "tokens = stop_removed_tokens\n",
    "# print(tokens)\n",
    "# tokens = list (set(tokens))\n",
    "# Making word frequency  in dictinary datastructure\n",
    "freqTable = dict()\n",
    "for word in tokens:\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n",
    "# printing the Frequency of Words\n",
    "\n",
    "# Tokenizing The Sentences\n",
    "sentences = text.split(u\"।\")\n",
    "\n",
    "# making sentenceValue dictionary and giving a sentenceValue(rank) through freqTable dictionary of words.\n",
    "sentenceValue = dict()\n",
    "for sentence in sentences:\n",
    "    for wordValue in freqTable:\n",
    "        if sentence in sentenceValue:\n",
    "            sentenceValue[sentence] += freqTable[wordValue]\n",
    "        else:\n",
    "            sentenceValue[sentence] = freqTable[wordValue]\n",
    "\n",
    "# Normalize the value of sentence rank as 0 to 1\n",
    "for sentence in sentenceValue:\n",
    "    sentenceValue[sentence] = (sentenceValue[sentence] * (1.000000)) / max(sentenceValue.values())\n",
    "\n",
    "# sentence length feature\n",
    "\n",
    "sentenceLength = dict()\n",
    "\n",
    "\n",
    "def sentence_length(sentences):\n",
    "    MinL = 4  # minm len of sentence\n",
    "    MaxL = 18  # maxm len of sentence\n",
    "    Mintheta = 0  # minm angle theta\n",
    "    Maxtheta = 180  # maxm angle theta\n",
    "    for sentence in sentences:\n",
    "        L = sentence.split()\n",
    "        L = len(L)\n",
    "        if ((L < MinL) or (L > MaxL)):  # if senLength less than MinLength or Grtr than MaxLen then ignore the sentence\n",
    "            sentenceLength[sentence] = 0\n",
    "        else:\n",
    "            Sl = math.sin((L - MinL) * ((Maxtheta - Mintheta) / (MaxL - MinL)))  # calculate the sentence\n",
    "            sentenceLength[sentence] = Sl\n",
    "    return sentenceLength\n",
    "\n",
    "\n",
    "sentence_length(sentences)  # calling sentence_length function\n",
    "\n",
    "# sentence position feature\n",
    "sentencePosition = dict()\n",
    "sentenceNumber = dict()\n",
    "\n",
    "\n",
    "def sentence_position(sentences):\n",
    "    TRSH = 0.01\n",
    "    Mintheta = 0\n",
    "    Maxtheta = 360\n",
    "    CP = 1\n",
    "    MinV = len(sentences) * TRSH\n",
    "    MaxV = len(sentences) * (1 - TRSH)\n",
    "    for sentence in sentences:\n",
    "        if ((CP == 1) or (CP == len(sentences))):  # if sentence postion is 1st or last then its important\n",
    "            sentencePosition[sentence] = 1\n",
    "            sentenceNumber[sentence] = CP\n",
    "        else:\n",
    "            SP = math.cos((CP - MinV) * ((Maxtheta - Mintheta) / (MaxV - MinV)))  # calculating sentence position\n",
    "            sentencePosition[sentence] = SP\n",
    "            sentenceNumber[sentence] = CP\n",
    "        CP = CP + 1\n",
    "    return sentencePosition\n",
    "\n",
    "\n",
    "sentence_position(sentences)\n",
    "\n",
    "# print(sentenceNumber)\n",
    "\n",
    "\n",
    "# sentence Similarity feature by Graph\n",
    "\n",
    "sentToken = []  # each sentence containg token\n",
    "for sent in sentences:\n",
    "    temp = sent.split()\n",
    "    f = open(\"stopwords.txt\", encoding=\"utf8\")\n",
    "    stopwords = [x.strip() for x in f.readlines()]\n",
    "    token = [i for i in temp if i not in stopwords]\n",
    "    sentToken.append(token)\n",
    "\n",
    "\n",
    "# print(sentToken)\n",
    "# retuen weight of two sentences\n",
    "def weight(i, j):\n",
    "    sent1 = sentToken[i]\n",
    "    sent2 = sentToken[j]\n",
    "    return len(list(set(sent1).intersection(sent2)))\n",
    "\n",
    "\n",
    "sentLen = len(sentences)\n",
    "\n",
    "sentencesGraph = [[0 for x in range(sentLen)] for y in range(sentLen)]\n",
    "for i in range(0, sentLen):\n",
    "    for j in range(0, sentLen):\n",
    "        if i != j:\n",
    "            sentencesGraph[i][j] = weight(i, j)\n",
    "        else:\n",
    "            sentencesGraph[i][j] = 0\n",
    "\n",
    "senSimlariy = []\n",
    "sum = 0\n",
    "for i in range(0, sentLen):\n",
    "    for j in range(0, sentLen):\n",
    "        sum += sentencesGraph[i][j]\n",
    "    senSimlariy.append(sum)\n",
    "    sum = 0\n",
    "sentencesSimilarity = dict()\n",
    "i = 0  # indexing the sentence similarity sentences\n",
    "for sentence in sentences:\n",
    "    sentencesSimilarity[sentence] = senSimlariy[i] / max(senSimlariy)\n",
    "    i += 1\n",
    "\n",
    "# sentence Feature add for ranking of sentences\n",
    "sentenceRanking = dict()\n",
    "\n",
    "\n",
    "def sentence_ranking(sentences):\n",
    "    f4 = sentencesSimilarity\n",
    "    f1 = sentenceValue\n",
    "    f2 = sentenceLength\n",
    "    f3 = sentencePosition\n",
    "    for sentence in sentences:\n",
    "        temp = abs(f1[sentence]) + abs(f2[sentence]) + abs(f3[sentence])  + abs(f4[sentence])\n",
    "        sentenceRanking[sentence] = temp\n",
    "    return sentenceRanking\n",
    "\n",
    "\n",
    "sentence_ranking(sentences)\n",
    "\n",
    "# function to calculate summary\n",
    "sentenceSummary = dict()\n",
    "\n",
    "\n",
    "\n",
    "def summary():\n",
    "    senLength = len(sentences)\n",
    "    percent = int(input(\"Enter the percentage of summary you want of original paragraph \"))\n",
    "    count = int(senLength * (percent / 100))\n",
    "    if count > senLength:\n",
    "        print(\"Wrong Input..must be less than original sentence length.\")\n",
    "\n",
    "    temp = 0\n",
    "    sentence_Ranking = sorted(sentenceRanking.items(), key=lambda t: t[1],\n",
    "                              reverse=True)  # sorting sentence_Rank dict in reverse order\n",
    "    for k in sentence_Ranking:\n",
    "        if temp < count:\n",
    "            sentenceSummary[sentenceNumber[k[0]]] = k[0]\n",
    "            temp = temp + 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "summary()  # calling summary function\n",
    "# print(sentenceSummary)\n",
    "print('\\n')\n",
    "sentence_summary = sorted(sentenceSummary.items())\n",
    "for x in sentence_summary:\n",
    "    print(x[1]+\"|\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
